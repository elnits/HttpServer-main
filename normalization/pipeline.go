package normalization

import (
	"fmt"
	"log"
	"time"

	"httpserver/database"
)

// ProcessingLevel —É—Ä–æ–≤–µ–Ω—å –æ–±—Ä–∞–±–æ—Ç–∫–∏
type ProcessingLevel string

const (
	LevelBasic      ProcessingLevel = "basic"
	LevelAIEnhanced ProcessingLevel = "ai_enhanced"
	LevelBenchmark  ProcessingLevel = "benchmark"
)

// PipelineStats —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã –ø–∞–π–ø–ª–∞–π–Ω–∞
type PipelineStats struct {
	TotalProcessed    int            `json:"total_processed"`
	BasicCount        int            `json:"basic_count"`
	AIEnhancedCount   int            `json:"ai_enhanced_count"`
	BenchmarkCount    int            `json:"benchmark_count"`
	AverageQuality    float64        `json:"average_quality"`
	QualityByLevel    map[string]float64 `json:"quality_by_level"`
	ProcessingTime    time.Duration  `json:"processing_time"`
}

// NormalizationPipeline —É–ø—Ä–∞–≤–ª—è–µ—Ç –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
type NormalizationPipeline struct {
	db               *database.DB
	normalizer       *Normalizer
	qualityValidator *QualityValidator
	events           chan<- string
	stats            *PipelineStats
}

// NewNormalizationPipeline —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –ø–∞–π–ø–ª–∞–π–Ω
func NewNormalizationPipeline(
	db *database.DB,
	normalizer *Normalizer,
	events chan<- string,
) *NormalizationPipeline {
	return &NormalizationPipeline{
		db:               db,
		normalizer:       normalizer,
		qualityValidator: NewQualityValidator(),
		events:           events,
		stats: &PipelineStats{
			QualityByLevel: make(map[string]float64),
		},
	}
}

// ProcessWithQuality –≤—ã–ø–æ–ª–Ω—è–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Å –æ—Ü–µ–Ω–∫–æ–π –∫–∞—á–µ—Å—Ç–≤–∞
func (p *NormalizationPipeline) ProcessWithQuality() error {
	startTime := time.Now()
	p.sendEvent("üîÑ –ó–∞–ø—É—Å–∫ –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –∫–∞—á–µ—Å—Ç–≤–∞...")
	log.Println("–ó–∞–ø—É—Å–∫ –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –∫–∞—á–µ—Å—Ç–≤–∞...")

	// –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω—è–µ–º –æ–±—ã—á–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
	if err := p.normalizer.ProcessNormalization(); err != nil {
		return fmt.Errorf("normalization failed: %w", err)
	}

	// –¢–µ–ø–µ—Ä—å –æ—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º —É—Ä–æ–≤–Ω–∏
	p.sendEvent("üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
	log.Println("–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

	if err := p.evaluateAndUpdateQuality(); err != nil {
		return fmt.Errorf("quality evaluation failed: %w", err)
	}

	p.stats.ProcessingTime = time.Since(startTime)

	// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
	p.sendFinalStats()

	return nil
}

// evaluateAndUpdateQuality –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç —É—Ä–æ–≤–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
func (p *NormalizationPipeline) evaluateAndUpdateQuality() error {
	// –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
	items, err := p.db.GetNormalizedItems(0, 0) // –í—Å–µ –∑–∞–ø–∏—Å–∏
	if err != nil {
		return fmt.Errorf("failed to get normalized items: %w", err)
	}

	p.sendEvent(fmt.Sprintf("–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è %d –∑–∞–ø–∏—Å–µ–π...", len(items)))

	totalQuality := 0.0
	levelQuality := make(map[string]float64)
	levelCounts := make(map[string]int)

	batchSize := 1000
	processedCount := 0

	for _, item := range items {
		// –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
		quality := p.qualityValidator.ValidateQuality(
			item.SourceName,
			item.NormalizedName,
			item.Category,
			item.AIConfidence,
			item.ProcessingLevel,
		)

		// –û–±–Ω–æ–≤–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å, –µ—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç benchmark –∫–∞—á–µ—Å—Ç–≤–∞
		newLevel := item.ProcessingLevel
		if quality.IsBenchmarkQuality && item.ProcessingLevel != "benchmark" {
			newLevel = "benchmark"

			// –û–±–Ω–æ–≤–ª—è–µ–º –≤ –ë–î
			if err := p.db.UpdateProcessingLevel(item.ID, "benchmark", quality.Overall); err != nil {
				log.Printf("Failed to update processing level for item %d: %v", item.ID, err)
			}
		}

		// –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
		totalQuality += quality.Overall
		levelQuality[newLevel] += quality.Overall
		levelCounts[newLevel]++

		// –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –ø–æ —É—Ä–æ–≤–Ω—è–º
		switch ProcessingLevel(newLevel) {
		case LevelBasic:
			p.stats.BasicCount++
		case LevelAIEnhanced:
			p.stats.AIEnhancedCount++
		case LevelBenchmark:
			p.stats.BenchmarkCount++
		}

		processedCount++

		// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –∫–∞–∂–¥—ã–µ 1000 –∑–∞–ø–∏—Å–µ–π
		if processedCount%batchSize == 0 {
			progress := float64(processedCount) / float64(len(items)) * 100
			p.sendEvent(fmt.Sprintf("–û—Ü–µ–Ω–µ–Ω–æ –∫–∞—á–µ—Å—Ç–≤–∞: %d –∏–∑ %d (%.1f%%)", processedCount, len(items), progress))
		}
	}

	p.stats.TotalProcessed = len(items)

	if len(items) > 0 {
		p.stats.AverageQuality = totalQuality / float64(len(items))
	}

	// –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ —É—Ä–æ–≤–Ω—è–º
	for level, count := range levelCounts {
		if count > 0 {
			p.stats.QualityByLevel[level] = levelQuality[level] / float64(count)
		}
	}

	return nil
}

// sendEvent –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ –∫–∞–Ω–∞–ª
func (p *NormalizationPipeline) sendEvent(message string) {
	if p.events != nil {
		select {
		case p.events <- message:
		default:
			// –ö–∞–Ω–∞–ª –ø–æ–ª–æ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
		}
	}
}

// sendFinalStats –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
func (p *NormalizationPipeline) sendFinalStats() {
	stats := fmt.Sprintf(
		"‚úÖ –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ %v\n"+
			"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n"+
			"  ‚Ä¢ –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: %d –∑–∞–ø–∏—Å–µ–π\n"+
			"  ‚Ä¢ –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å: %d (%.1f%%)\n"+
			"  ‚Ä¢ AI —É–ª—É—á—à–µ–Ω–æ: %d (%.1f%%)\n"+
			"  ‚Ä¢ –≠—Ç–∞–ª–æ–Ω–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ: %d (%.1f%%)\n"+
			"  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: %.2f",
		p.stats.ProcessingTime,
		p.stats.TotalProcessed,
		p.stats.BasicCount,
		float64(p.stats.BasicCount)/float64(p.stats.TotalProcessed)*100,
		p.stats.AIEnhancedCount,
		float64(p.stats.AIEnhancedCount)/float64(p.stats.TotalProcessed)*100,
		p.stats.BenchmarkCount,
		float64(p.stats.BenchmarkCount)/float64(p.stats.TotalProcessed)*100,
		p.stats.AverageQuality,
	)

	p.sendEvent(stats)
	log.Println(stats)
}

// GetStats –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–∞–π–ø–ª–∞–π–Ω–∞
func (p *NormalizationPipeline) GetStats() *PipelineStats {
	return p.stats
}
