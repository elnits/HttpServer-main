package normalization

import (
	"encoding/json"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"time"

	"httpserver/database"
)

// AIConfig –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è AI –æ–±—Ä–∞–±–æ—Ç–∫–∏
type AIConfig struct {
	Enabled        bool
	MinConfidence  float64
	RateLimitDelay time.Duration
	MaxRetries     int
	// Batch processing settings
	BatchEnabled      bool          // –í–∫–ª—é—á–∏—Ç—å –±–∞—Ç—á–µ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É AI –∑–∞–ø—Ä–æ—Å–æ–≤
	BatchSize         int           // –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)
	BatchFlushInterval time.Duration // –ò–Ω—Ç–µ—Ä–≤–∞–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
}

// NormalizationCheckpoint —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
// –ü–æ–∑–≤–æ–ª—è–µ—Ç –≤–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–æ—Å–ª–µ —Å–±–æ—è
type NormalizationCheckpoint struct {
	ProcessedCount  int       `json:"processed_count"`  // –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
	LastProcessedID int       `json:"last_processed_id"` // ID –ø–æ—Å–ª–µ–¥–Ω–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏
	TotalCount      int       `json:"total_count"`      // –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
	StartTime       time.Time `json:"start_time"`       // –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
	LastSaveTime    time.Time `json:"last_save_time"`   // –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è checkpoint
	UploadID        int       `json:"upload_id"`        // ID –≤—ã–≥—Ä—É–∑–∫–∏
	BatchSize       int       `json:"batch_size"`       // –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
}

// Normalizer –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
type Normalizer struct {
	db                     *database.DB
	categorizer            *Categorizer
	nameNormalizer         *NameNormalizer
	aiNormalizer           *AINormalizer
	hierarchicalClassifier *HierarchicalClassifier
	events                 chan<- string
	useAI                  bool
	aiConfig               *AIConfig
	// –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
	sourceTable     string
	referenceColumn string
	codeColumn      string
	nameColumn      string
	// Streaming –∏ checkpoints
	enableCheckpoints bool
	checkpointDir     string
	currentCheckpoint *NormalizationCheckpoint // –¢–µ–∫—É—â–∏–π checkpoint –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
}

// groupKey –∫–ª—é—á –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∑–∞–ø–∏—Å–µ–π
type groupKey struct {
	category       string
	normalizedName string
}

// groupValue –∑–Ω–∞—á–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã —Å AI –∏ –ö–ü–í–≠–î –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
type groupValue struct {
	items           []*database.CatalogItem
	aiConfidence    float64
	aiReasoning     string
	processingLevel string
	kpvedCode       string
	kpvedName       string
	kpvedConfidence float64
	attributes      map[string][]*database.ItemAttribute // code -> attributes
}

// NewNormalizer —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä
func NewNormalizer(db *database.DB, events chan<- string, aiConfig *AIConfig) *Normalizer {
	normalizer := &Normalizer{
		db:              db,
		categorizer:     NewCategorizer(),
		nameNormalizer:  NewNameNormalizer(),
		events:          events,
		useAI:           aiConfig != nil && aiConfig.Enabled,
		aiConfig:        aiConfig,
		// –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
		sourceTable:     "catalog_items",
		referenceColumn: "reference",
		codeColumn:      "code",
		nameColumn:      "name",
		// –í–∫–ª—é—á–∞–µ–º checkpoints –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
		enableCheckpoints: true,
		checkpointDir:     "./checkpoints",
	}

	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
	if normalizer.useAI {
		apiKey := os.Getenv("ARLIAI_API_KEY")
		if apiKey != "" {
			normalizer.aiNormalizer = NewAINormalizer(apiKey)
			normalizer.sendEvent("‚úì AI –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞")
			log.Println("AI –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞")

			// –í–∫–ª—é—á–∞–µ–º –±–∞—Ç—á–µ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É AI –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞
			if normalizer.aiConfig.BatchEnabled {
				batchSize := normalizer.aiConfig.BatchSize
				if batchSize == 0 {
					batchSize = 10 // –î–µ—Ñ–æ–ª—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
				}
				flushInterval := normalizer.aiConfig.BatchFlushInterval
				if flushInterval == 0 {
					flushInterval = 5 * time.Second // –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
				}
				normalizer.aiNormalizer.EnableBatchProcessing(batchSize, flushInterval)
				normalizer.sendEvent(fmt.Sprintf("‚úì –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ AI –≤–∫–ª—é—á–µ–Ω–∞ (—Ä–∞–∑–º–µ—Ä=%d, –∏–Ω—Ç–µ—Ä–≤–∞–ª=%v)", batchSize, flushInterval))
			}

			// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –ö–ü–í–≠–î –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
			aiClient := normalizer.aiNormalizer.aiClient
			hierarchicalClassifier, err := NewHierarchicalClassifier(db, aiClient)
			if err != nil {
				log.Printf("Warning: Failed to initialize hierarchical KPVED classifier: %v", err)
				normalizer.sendEvent("‚ö† –ö–ü–í–≠–î –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
			} else {
				normalizer.hierarchicalClassifier = hierarchicalClassifier
				normalizer.sendEvent("‚úì –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –ö–ü–í–≠–î –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤–∫–ª—é—á–µ–Ω")
				log.Println("–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –ö–ü–í–≠–î –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤–∫–ª—é—á–µ–Ω")
			}
		} else {
			normalizer.sendEvent("‚ö† ARLIAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, AI –æ—Ç–∫–ª—é—á–µ–Ω")
			log.Println("ARLIAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, AI –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞")
			normalizer.useAI = false
		}
	}

	return normalizer
}

// SetSourceConfig —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö
func (n *Normalizer) SetSourceConfig(tableName, referenceCol, codeCol, nameCol string) {
	n.sourceTable = tableName
	n.referenceColumn = referenceCol
	n.codeColumn = codeCol
	n.nameColumn = nameCol
	log.Printf("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞: —Ç–∞–±–ª–∏—Ü–∞=%s, reference=%s, code=%s, name=%s",
		tableName, referenceCol, codeCol, nameCol)
}

// SetHierarchicalClassifier —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ö–ü–í–≠–î
func (n *Normalizer) SetHierarchicalClassifier(classifier *HierarchicalClassifier) {
	n.hierarchicalClassifier = classifier
	log.Println("–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –ö–ü–í–≠–î –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
}

// sendEvent –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ –∫–∞–Ω–∞–ª, –µ—Å–ª–∏ –æ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω
func (n *Normalizer) sendEvent(message string) {
	if n.events != nil {
		select {
		case n.events <- message:
		default:
			// –ö–∞–Ω–∞–ª –ø–æ–ª–æ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–±—ã—Ç–∏–µ
		}
	}
}

// ProcessNormalization –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
func (n *Normalizer) ProcessNormalization() error {
	startTime := time.Now()
	n.sendEvent("–ù–∞—á–∞–ª–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö...")
	log.Printf("–ù–∞—á–∞–ª–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö...")

	// 1. –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
	n.sendEvent("–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ catalog_items...")
	log.Printf("–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ catalog_items...")
	if err := n.db.CleanOldCatalogItems(); err != nil {
		n.sendEvent(fmt.Sprintf("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: %v", err))
		return fmt.Errorf("failed to clean old catalog items: %w", err)
	}
	n.sendEvent("–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
	log.Printf("–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

	// 2. –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
	n.sendEvent(fmt.Sprintf("–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ %s...", n.sourceTable))
	log.Printf("–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ %s (ref=%s, code=%s, name=%s)...",
		n.sourceTable, n.referenceColumn, n.codeColumn, n.nameColumn)
	items, err := n.db.GetCatalogItemsFromTable(n.sourceTable, n.referenceColumn, n.codeColumn, n.nameColumn)
	if err != nil {
		n.sendEvent(fmt.Sprintf("–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–ø–∏—Å–µ–π: %v", err))
		return fmt.Errorf("failed to get catalog items: %w", err)
	}
	n.sendEvent(fmt.Sprintf("–ü–æ–ª—É—á–µ–Ω–æ %d –∑–∞–ø–∏—Å–µ–π –∏–∑ %s", len(items), n.sourceTable))
	log.Printf("–ü–æ–ª—É—á–µ–Ω–æ %d –∑–∞–ø–∏—Å–µ–π –∏–∑ %s", len(items), n.sourceTable)

	// CHECKPOINT: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è checkpoint –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
	checkpoint := &NormalizationCheckpoint{
		ProcessedCount:  0,
		LastProcessedID: 0,
		TotalCount:      len(items),
		StartTime:       startTime,
		LastSaveTime:    startTime,
		UploadID:        1, // TODO: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π upload_id –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
		BatchSize:       1000,
	}
	n.currentCheckpoint = checkpoint // –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

	// 3. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ –ø–æ (–∫–∞—Ç–µ–≥–æ—Ä–∏—è, normalized_name)
	n.sendEvent("–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–∞–ø–∏—Å–µ–π...")
	log.Printf("–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∑–∞–ø–∏—Å–µ–π...")

	groups := make(map[groupKey]*groupValue)
	processedCount := 0
	aiProcessedCount := 0

	for _, item := range items {
		// –ë–∞–∑–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–ø—Ä–∞–≤–∏–ª–∞) —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∞—Ç—Ä–∏–±—É—Ç–æ–≤
		category := n.categorizer.Categorize(item.Name)
		normalizedName, attributes := n.nameNormalizer.ExtractAttributes(item.Name)
		if normalizedName == "" {
			normalizedName = item.Name // –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è, –µ—Å–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–ª–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
		}
		aiConfidence := 0.0
		aiReasoning := ""
		processingLevel := "basic"

		// AI –æ–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
		if n.useAI && n.aiNormalizer != nil && n.aiNormalizer.RequiresAI(item.Name, category) {
			aiResult, err := n.processWithAI(item.Name)
			if err != nil {
				n.sendEvent(fmt.Sprintf("‚ö† AI –æ—à–∏–±–∫–∞ –¥–ª—è '%s': %v, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª–∞", item.Name, err))
				log.Printf("AI –æ—à–∏–±–∫–∞ –¥–ª—è '%s': %v, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª–∞", item.Name, err)
			} else if aiResult.Confidence >= n.aiConfig.MinConfidence {
				// –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç AI –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è
				category = aiResult.Category
				normalizedName = aiResult.NormalizedName
				aiConfidence = aiResult.Confidence
				aiReasoning = aiResult.Reasoning
				processingLevel = "ai_enhanced"
				aiProcessedCount++

				if aiProcessedCount%10 == 0 {
					n.sendEvent(fmt.Sprintf("ü§ñ AI –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ %d –∑–∞–ø–∏—Å–µ–π", aiProcessedCount))
				}
			} else {
				n.sendEvent(fmt.Sprintf("‚ö† AI –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (%.2f) –¥–ª—è '%s', –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª–∞", aiResult.Confidence, item.Name))
			}
		}

		// –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –≥—Ä—É–ø–ø—ã –î–û –ö–ü–í–≠–î –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–ª—é—á–∞
		// –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏–º—è
		key := groupKey{category: category, normalizedName: normalizedName}
		group, exists := groups[key]

		// –ö–ü–í–≠–î –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¢–û–õ–¨–ö–û –¥–ª—è –Ω–æ–≤—ã—Ö –≥—Ä—É–ø–ø
		// –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø—ã –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ö–ü–í–≠–î –∫–æ–¥—ã
		kpvedCode := ""
		kpvedName := ""
		kpvedConfidence := 0.0

		if !exists {
			// –î–ª—è –Ω–æ–≤–æ–π –≥—Ä—É–ø–ø—ã –≤—ã–ø–æ–ª–Ω—è–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫—É—é –ö–ü–í–≠–î –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
			// –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ö–ü–í–≠–î –∫–∞–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–≥–æ Categorizer
			if n.hierarchicalClassifier != nil {
				kpvedResult, err := n.hierarchicalClassifier.Classify(normalizedName, category)
				if err != nil {
					log.Printf("Warning: Hierarchical KPVED classification failed for '%s': %v, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é", normalizedName, err)
				} else {
					kpvedCode = kpvedResult.FinalCode
					kpvedName = kpvedResult.FinalName
					kpvedConfidence = kpvedResult.FinalConfidence
					
					// –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –ö–ü–í–≠–î –∫–∞–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏—é, –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞
					// –ù–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –∏–∑–º–µ–Ω–∏—Ç –∫–ª—é—á –≥—Ä—É–ø–ø—ã (—á—Ç–æ–±—ã –Ω–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã)
					if kpvedName != "" && kpvedConfidence >= 0.5 {
						// –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–æ–∑–¥–∞—Å—Ç –ª–∏ —ç—Ç–æ –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É
						newKey := groupKey{category: kpvedName, normalizedName: normalizedName}
						if _, newKeyExists := groups[newKey]; !newKeyExists {
							// –ò—Å–ø–æ–ª—å–∑—É–µ–º –ö–ü–í–≠–î –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å–æ–∑–¥–∞—Å—Ç –¥—É–±–ª–∏–∫–∞—Ç
							category = kpvedName
							key = newKey
						}
					}
					
					log.Printf("üìä KPVED (–∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π): %s -> %s (%s) [%.2f] –∑–∞ %dms (%d —à–∞–≥–æ–≤, %d AI –≤—ã–∑–æ–≤–æ–≤)",
						normalizedName, kpvedCode, kpvedName, kpvedConfidence,
						kpvedResult.TotalDuration, len(kpvedResult.Steps), kpvedResult.AICallsCount)
				}
			}

			// –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É —Å –ö–ü–í–≠–î –¥–∞–Ω–Ω—ã–º–∏
			group = &groupValue{
				items:           make([]*database.CatalogItem, 0),
				aiConfidence:    aiConfidence,
				aiReasoning:     aiReasoning,
				processingLevel: processingLevel,
				kpvedCode:       kpvedCode,
				kpvedName:       kpvedName,
				kpvedConfidence: kpvedConfidence,
				attributes:      make(map[string][]*database.ItemAttribute),
			}
			groups[key] = group
		} else {
			// –î–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –≥—Ä—É–ø–ø—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –ö–ü–í–≠–î –¥–∞–Ω–Ω—ã–µ
			kpvedCode = group.kpvedCode
			kpvedName = group.kpvedName
			kpvedConfidence = group.kpvedConfidence
		}

		// –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ –≥—Ä—É–ø–ø—É
		group.items = append(group.items, item)
		// –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
		if len(attributes) > 0 {
			group.attributes[item.Code] = attributes
		}
		processedCount++

		// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –∫–∞–∂–¥—ã–µ 1000 –∑–∞–ø–∏—Å–µ–π
		if processedCount%1000 == 0 {
			progress := float64(processedCount) / float64(len(items)) * 100
			n.sendEvent(fmt.Sprintf("–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ %d –∏–∑ %d –∑–∞–ø–∏—Å–µ–π (%.1f%%)", processedCount, len(items), progress))
		}
	}

	groupCount := n.countGroups(groups)
	message := fmt.Sprintf("–°–æ–∑–¥–∞–Ω–æ %d –≥—Ä—É–ø–ø", groupCount)
	if aiProcessedCount > 0 {
		message += fmt.Sprintf(" (AI —É–ª—É—á—à–µ–Ω–æ: %d –∑–∞–ø–∏—Å–µ–π)", aiProcessedCount)
	}
	n.sendEvent(message)
	log.Print(message)

	// 4. –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
	n.sendEvent("–í—Å—Ç–∞–≤–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
	log.Printf("–í—Å—Ç–∞–≤–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
	totalInserted := 0
	batchSize := 1000
	var batch []*database.NormalizedItem
	// –ú–∞–ø–∞ –¥–ª—è —Å–≤—è–∑–∏ –∫–æ–¥–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ —Å –µ–≥–æ –≥—Ä—É–ø–ø–æ–π (–¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –∞—Ç—Ä–∏–±—É—Ç–∞–º)
	codeToGroup := make(map[string]*groupValue)

	// –ü–æ–ª—É—á–∞–µ–º StatsCollector –¥–ª—è –∑–∞–ø–∏—Å–∏ –º–µ—Ç—Ä–∏–∫
	var statsCollector *StatsCollector
	if n.aiNormalizer != nil {
		statsCollector = n.aiNormalizer.GetStatsCollector()
	}

	// –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ –∑–∞–ø–∏—Å—å
	elapsedSoFar := time.Since(startTime)
	var avgTimePerItem time.Duration
	if len(items) > 0 {
		avgTimePerItem = elapsedSoFar / time.Duration(len(items))
	} else {
		avgTimePerItem = 0
	}

	for key, group := range groups {
		// –û–ø—Ä–µ–¥–µ–ª—è–µ–º normalized_reference = normalized_name
		normalizedReference := key.normalizedName
		mergedCount := len(group.items)

		// –î–ª—è –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏ –≤ –≥—Ä—É–ø–ø–µ —Å–æ–∑–¥–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –∑–∞–ø–∏—Å—å
		for _, item := range group.items {
			normalizedItem := &database.NormalizedItem{
				SourceReference:     item.Reference,
				SourceName:          item.Name,
				Code:                item.Code,
				NormalizedName:      key.normalizedName,
				NormalizedReference: normalizedReference,
				Category:            key.category,
				MergedCount:         mergedCount,
				AIConfidence:        group.aiConfidence,
				AIReasoning:         group.aiReasoning,
				ProcessingLevel:     group.processingLevel,
				KpvedCode:           group.kpvedCode,
				KpvedName:           group.kpvedName,
				KpvedConfidence:     group.kpvedConfidence,
			}

			batch = append(batch, normalizedItem)
			// –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤—è–∑—å –∫–æ–¥–∞ —Å –≥—Ä—É–ø–ø–æ–π –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –∞—Ç—Ä–∏–±—É—Ç–∞–º
			if item.Code != "" {
				codeToGroup[item.Code] = group
			}

			// –í—Å—Ç–∞–≤–ª—è–µ–º –ø–∞–∫–µ—Ç–æ–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
			if len(batch) >= batchSize {
				// –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –î–£–ë–õ–ò–ö–ê–¢–û–í: –ø—Ä–æ–≤–µ—Ä—è–µ–º –±–∞—Ç—á –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –≤ –ë–î
				// –î—É–±–ª–∏–∫–∞—Ç—ã —Å confidence >= 0.95 –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏–∑ –±–∞—Ç—á–∞
				// –í–º–µ—Å—Ç–æ –≤—Å—Ç–∞–≤–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–∞ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è merged_count —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å–∏
				filteredBatch, err := n.filterDuplicatesFromBatch(batch)
				if err != nil {
					n.sendEvent(fmt.Sprintf("–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: %v", err))
					return fmt.Errorf("failed to filter duplicates: %w", err)
				}

				// –°–æ–±–∏—Ä–∞–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –±–∞—Ç—á–∞
				batchAttributes := make(map[string][]*database.ItemAttribute)
				for _, normalizedItem := range filteredBatch {
					if normalizedItem.Code != "" {
						if group, ok := codeToGroup[normalizedItem.Code]; ok {
							if attrs, ok := group.attributes[normalizedItem.Code]; ok && len(attrs) > 0 {
								batchAttributes[normalizedItem.Code] = attrs
							}
						}
					}
				}

				// –ê–¢–û–ú–ê–†–ù–ê–Ø –≤—Å—Ç–∞–≤–∫–∞: items + attributes –≤ –û–î–ù–û–ô —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
				// –ï—Å–ª–∏ –ª—é–±–∞—è —á–∞—Å—Ç—å —É–ø–∞–¥–µ—Ç - –æ—Ç–∫–∞—Ç–∏—Ç—Å—è –í–°–ï (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —á–∞—Å—Ç–∏—á–Ω—É—é –≤—Å—Ç–∞–≤–∫—É)
				_, err = n.db.InsertNormalizedItemsWithAttributesBatch(filteredBatch, batchAttributes)
				if err != nil {
					n.sendEvent(fmt.Sprintf("–û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ –ø–∞–∫–µ—Ç–∞: %v", err))
					return fmt.Errorf("failed to insert batch: %w", err)
				}

				// –û—á–∏—â–∞–µ–º –º–∞–ø—É –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –±–∞—Ç—á–∞
				codeToGroup = make(map[string]*groupValue)

				// –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –†–ï–ê–õ–¨–ù–û –í–°–¢–ê–í–õ–ï–ù–ù–û–ô –∑–∞–ø–∏—Å–∏ (–±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
				if statsCollector != nil {
					for _, normalizedItem := range filteredBatch {
						qualityScore := normalizedItem.AIConfidence
						if qualityScore == 0.0 {
							// –î–ª—è –±–∞–∑–æ–≤–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –±–∞–ª–ª
							qualityScore = 0.5
						}
						statsCollector.RecordNormalization(
							normalizedItem.ProcessingLevel,
							qualityScore,
							avgTimePerItem,
						)
					}
				}

				totalInserted += len(filteredBatch)
				progress := float64(totalInserted) / float64(len(items)) * 100
				n.sendEvent(fmt.Sprintf("–í—Å—Ç–∞–≤–ª–µ–Ω–æ %d –∑–∞–ø–∏—Å–µ–π (–≤—Å–µ–≥–æ: %d, %.1f%%)", len(filteredBatch), totalInserted, progress))
				log.Printf("–í—Å—Ç–∞–≤–ª–µ–Ω–æ %d –∑–∞–ø–∏—Å–µ–π (–≤—Å–µ–≥–æ: %d)", len(filteredBatch), totalInserted)

				// CHECKPOINT: –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞
				checkpoint.ProcessedCount = totalInserted
				n.currentCheckpoint = checkpoint // –û–±–Ω–æ–≤–ª—è–µ–º –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
				if err := n.saveCheckpoint(checkpoint); err != nil {
					log.Printf("‚ö† –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å checkpoint: %v", err)
				}

				batch = batch[:0] // –û—á–∏—â–∞–µ–º –ø–∞–∫–µ—Ç
			}
		}
	}

	// –í—Å—Ç–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∑–∞–ø–∏—Å–∏
	if len(batch) > 0 {
		// –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –î–£–ë–õ–ò–ö–ê–¢–û–í –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –±–∞—Ç—á–∞
		filteredBatch, err := n.filterDuplicatesFromBatch(batch)
		if err != nil {
			n.sendEvent(fmt.Sprintf("–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º –±–∞—Ç—á–µ: %v", err))
			return fmt.Errorf("failed to filter duplicates in final batch: %w", err)
		}

		// –°–æ–±–∏—Ä–∞–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –±–∞—Ç—á–∞
		batchAttributes := make(map[string][]*database.ItemAttribute)
		for _, normalizedItem := range filteredBatch {
			if normalizedItem.Code != "" {
				if group, ok := codeToGroup[normalizedItem.Code]; ok {
					if attrs, ok := group.attributes[normalizedItem.Code]; ok && len(attrs) > 0 {
						batchAttributes[normalizedItem.Code] = attrs
					}
				}
			}
		}

		// –ê–¢–û–ú–ê–†–ù–ê–Ø –≤—Å—Ç–∞–≤–∫–∞: items + attributes –≤ –û–î–ù–û–ô —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
		_, err = n.db.InsertNormalizedItemsWithAttributesBatch(filteredBatch, batchAttributes)
		if err != nil {
			n.sendEvent(fmt.Sprintf("–û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞: %v", err))
			return fmt.Errorf("failed to insert final batch: %w", err)
		}

		// –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –†–ï–ê–õ–¨–ù–û –í–°–¢–ê–í–õ–ï–ù–ù–´–• –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –∑–∞–ø–∏—Å–µ–π
		if statsCollector != nil {
			for _, normalizedItem := range filteredBatch {
				qualityScore := normalizedItem.AIConfidence
				if qualityScore == 0.0 {
					// –î–ª—è –±–∞–∑–æ–≤–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –±–∞–ª–ª
					qualityScore = 0.5
				}
				statsCollector.RecordNormalization(
					normalizedItem.ProcessingLevel,
					qualityScore,
					avgTimePerItem,
				)
			}
		}

		totalInserted += len(filteredBatch)
		n.sendEvent(fmt.Sprintf("–í—Å—Ç–∞–≤–ª–µ–Ω–æ %d –∑–∞–ø–∏—Å–µ–π (–≤—Å–µ–≥–æ: %d)", len(filteredBatch), totalInserted))
		log.Printf("–í—Å—Ç–∞–≤–ª–µ–Ω–æ %d –∑–∞–ø–∏—Å–µ–π (–≤—Å–µ–≥–æ: %d)", len(filteredBatch), totalInserted)

		// CHECKPOINT: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
		checkpoint.ProcessedCount = totalInserted
		n.currentCheckpoint = checkpoint // –û–±–Ω–æ–≤–ª—è–µ–º –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
		if err := n.saveCheckpoint(checkpoint); err != nil {
			log.Printf("‚ö† –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π checkpoint: %v", err)
		}
	}

	elapsed := time.Since(startTime)
	message = fmt.Sprintf("–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ %v. –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: %d –∑–∞–ø–∏—Å–µ–π", elapsed, totalInserted)
	n.sendEvent(message)
	log.Print(message)

	// CHECKPOINT: –£–¥–∞–ª—è–µ–º checkpoint –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
	if err := n.deleteCheckpoint(checkpoint.UploadID); err != nil {
		log.Printf("‚ö† –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å checkpoint: %v", err)
	} else {
		log.Printf("‚úì Checkpoint —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏")
	}

	// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É AI –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è
	if n.useAI && n.aiNormalizer != nil {
		stats := n.aiNormalizer.GetStats()
		aiMessage := fmt.Sprintf("ü§ñ AI –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: –í—ã–∑–æ–≤–æ–≤=%d, –ö—ç—à Hit Rate=%.1f%%, –û—à–∏–±–æ–∫=%d, –°—Ä–µ–¥–Ω—è—è –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å=%v",
			stats.TotalCalls, stats.CacheHitRate(), stats.Errors, stats.AvgLatency())
		n.sendEvent(aiMessage)
		log.Print(aiMessage)
	}

	return nil
}

// countGroups –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä—É–ø–ø
func (n *Normalizer) countGroups(groups map[groupKey]*groupValue) int {
	return len(groups)
}

// processWithAI –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é AI —Å retry logic
func (n *Normalizer) processWithAI(name string) (*AIResult, error) {
	var lastErr error
	maxRetries := n.aiConfig.MaxRetries
	if maxRetries == 0 {
		maxRetries = 3 // default
	}

	for attempt := 0; attempt < maxRetries; attempt++ {
		if attempt > 0 {
			// –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
			time.Sleep(n.aiConfig.RateLimitDelay)
		}

		result, err := n.aiNormalizer.NormalizeWithAI(name)
		if err == nil {
			return result, nil
		}
		lastErr = err
		log.Printf("AI –ø–æ–ø—ã—Ç–∫–∞ %d/%d –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è '%s': %v", attempt+1, maxRetries, name, err)
	}

	return nil, fmt.Errorf("–≤—Å–µ %d –ø–æ–ø—ã—Ç–æ–∫ AI –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å: %v", maxRetries, lastErr)
}

// GetAINormalizer –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç AI –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ
func (n *Normalizer) GetAINormalizer() *AINormalizer {
	return n.aiNormalizer
}

// filterDuplicatesFromBatch —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ –±–∞—Ç—á–∞ –ø–µ—Ä–µ–¥ –≤—Å—Ç–∞–≤–∫–æ–π
// –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –∑–∞–ø–∏—Å—è–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –£–ñ–ï –≤ –ë–î
// –î–ª—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (confidence >= 0.95):
//   - –£–¥–∞–ª—è–µ—Ç –∏–∑ –±–∞—Ç—á–∞
//   - –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç merged_count —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å–∏ –≤ –ë–î
// –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–π –±–∞—Ç—á –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
func (n *Normalizer) filterDuplicatesFromBatch(batch []*database.NormalizedItem) ([]*database.NormalizedItem, error) {
	if len(batch) == 0 {
		return batch, nil
	}

	// 1. –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ normalized_name –∏–∑ –±–∞—Ç—á–∞
	uniqueNames := make(map[string]bool)
	for _, item := range batch {
		if item.NormalizedName != "" {
			uniqueNames[item.NormalizedName] = true
		}
	}

	// –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–∞–π—Å
	names := make([]string, 0, len(uniqueNames))
	for name := range uniqueNames {
		names = append(names, name)
	}

	if len(names) == 0 {
		return batch, nil
	}

	// 2. –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∏–∑ –ë–î —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏ —Å –ø–æ—Ö–æ–∂–∏–º–∏ –∏–º–µ–Ω–∞–º–∏
	existingItems, err := n.db.GetNormalizedItemsBySimilarNames(names)
	if err != nil {
		return nil, fmt.Errorf("failed to get existing items: %w", err)
	}

	// –ï—Å–ª–∏ –≤ –ë–î –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞—Ç—á –∫–∞–∫ –µ—Å—Ç—å
	if len(existingItems) == 0 {
		return batch, nil
	}

	// 3. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º existing items –≤ —Ñ–æ—Ä–º–∞—Ç DuplicateItem –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
	existingDupItems := make([]DuplicateItem, len(existingItems))
	for i, item := range existingItems {
		existingDupItems[i] = DuplicateItem{
			ID:              item.ID,
			Code:            item.Code,
			NormalizedName:  item.NormalizedName,
			Category:        item.Category,
			QualityScore:    item.QualityScore,
			MergedCount:     item.MergedCount,
			ProcessingLevel: item.ProcessingLevel,
		}
	}

	// 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –±–∞—Ç—á–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∑–∞–ø–∏—Å—è–º–∏
	analyzer := NewDuplicateAnalyzer()
	// –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è exact matching, —á—Ç–æ–±—ã –ª–æ–≤–∏—Ç—å –±–æ–ª—å—à–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
	analyzer.exactThreshold = 0.95
	analyzer.semanticThreshold = 0.95

	// –ú–∞—Ä–∫–∏—Ä—É–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –±–∞—Ç—á–∞, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏
	toRemove := make(map[int]bool) // –∏–Ω–¥–µ–∫—Å—ã —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –±–∞—Ç—á–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
	duplicatesFound := 0

	for batchIdx, batchItem := range batch {
		if batchItem.NormalizedName == "" {
			continue
		}

		// –°–æ–∑–¥–∞–µ–º DuplicateItem –¥–ª—è —ç–ª–µ–º–µ–Ω—Ç–∞ –±–∞—Ç—á–∞ (–±–µ–∑ ID, —Ç.–∫. –µ—â–µ –Ω–µ –≤ –ë–î)
		batchDupItem := DuplicateItem{
			ID:              -1, // –í—Ä–µ–º–µ–Ω–Ω—ã–π ID
			Code:            batchItem.Code,
			NormalizedName:  batchItem.NormalizedName,
			Category:        batchItem.Category,
			QualityScore:    0.0,
			MergedCount:     batchItem.MergedCount,
			ProcessingLevel: batchItem.ProcessingLevel,
		}

		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –∫–∞–∂–¥–æ–π —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å—å—é
		for _, existingItem := range existingDupItems {
			// –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
			testItems := []DuplicateItem{batchDupItem, existingItem}
			groups := analyzer.AnalyzeDuplicates(testItems)

			// –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–∞ –≥—Ä—É–ø–ø–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
			for _, group := range groups {
				if group.Confidence >= 0.95 && len(group.Items) >= 2 {
					// –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ –≥—Ä—É–ø–ø–µ
					hasBatch := false
					hasExisting := false
					for _, item := range group.Items {
						if item.ID == -1 {
							hasBatch = true
						} else {
							hasExisting = true
						}
					}

					if hasBatch && hasExisting {
						// –ù–∞—à–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç! –ü–æ–º–µ—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç –±–∞—Ç—á–∞ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ
						toRemove[batchIdx] = true
						duplicatesFound++

						// –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º merged_count —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å–∏
						err := n.db.IncrementMergedCount(existingItem.ID)
						if err != nil {
							log.Printf("–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –Ω–µ —É–¥–∞–ª–æ—Å—å —É–≤–µ–ª–∏—á–∏—Ç—å merged_count –¥–ª—è –∑–∞–ø–∏—Å–∏ %d: %v", existingItem.ID, err)
						} else {
							log.Printf("–ù–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: '%s' (–±–∞—Ç—á) —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∑–∞–ø–∏—Å—å—é ID=%d –≤ –ë–î (confidence=%.2f). Merged_count —É–≤–µ–ª–∏—á–µ–Ω.", batchItem.NormalizedName, existingItem.ID, group.Confidence)
						}

						// –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ü–∏–∫–ª, —Ç.–∫. –¥—É–±–ª–∏–∫–∞—Ç —É–∂–µ –Ω–∞–π–¥–µ–Ω
						break
					}
				}
			}

			// –ï—Å–ª–∏ —ç–ª–µ–º–µ–Ω—Ç —É–∂–µ –ø–æ–º–µ—á–µ–Ω –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ, –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–ª—å—à–µ
			if toRemove[batchIdx] {
				break
			}
		}
	}

	// 5. –§–∏–ª—å—Ç—Ä—É–µ–º –±–∞—Ç—á, —É–¥–∞–ª—è—è –¥—É–±–ª–∏–∫–∞—Ç—ã
	if len(toRemove) == 0 {
		return batch, nil
	}

	filtered := make([]*database.NormalizedItem, 0, len(batch)-len(toRemove))
	for i, item := range batch {
		if !toRemove[i] {
			filtered = append(filtered, item)
		}
	}

	log.Printf("–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: –Ω–∞–π–¥–µ–Ω–æ %d –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, —É–¥–∞–ª–µ–Ω–æ –∏–∑ –±–∞—Ç—á–∞. –û—Å—Ç–∞–ª–æ—Å—å %d –∑–∞–ø–∏—Å–µ–π –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏.", duplicatesFound, len(filtered))
	n.sendEvent(fmt.Sprintf("–ù–∞–π–¥–µ–Ω–æ –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ %d –¥—É–±–ª–∏–∫–∞—Ç–æ–≤", duplicatesFound))

	return filtered, nil
}

// --- –ú–µ—Ç–æ–¥—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å checkpoints ---

// getCheckpointPath –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É checkpoint –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ uploadID
func (n *Normalizer) getCheckpointPath(uploadID int) string {
	return filepath.Join(n.checkpointDir, fmt.Sprintf("checkpoint_%d.json", uploadID))
}

// saveCheckpoint —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤ checkpoint —Ñ–∞–π–ª
func (n *Normalizer) saveCheckpoint(checkpoint *NormalizationCheckpoint) error {
	if !n.enableCheckpoints {
		return nil
	}

	// –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è checkpoints, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
	if err := os.MkdirAll(n.checkpointDir, 0755); err != nil {
		return fmt.Errorf("failed to create checkpoint directory: %w", err)
	}

	checkpoint.LastSaveTime = time.Now()

	// –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º checkpoint –≤ JSON
	data, err := json.MarshalIndent(checkpoint, "", "  ")
	if err != nil {
		return fmt.Errorf("failed to marshal checkpoint: %w", err)
	}

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
	checkpointPath := n.getCheckpointPath(checkpoint.UploadID)
	if err := os.WriteFile(checkpointPath, data, 0644); err != nil {
		return fmt.Errorf("failed to write checkpoint file: %w", err)
	}

	log.Printf("Checkpoint —Å–æ—Ö—Ä–∞–Ω–µ–Ω: %d/%d –∑–∞–ø–∏—Å–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ (%.1f%%)",
		checkpoint.ProcessedCount, checkpoint.TotalCount,
		float64(checkpoint.ProcessedCount)/float64(checkpoint.TotalCount)*100)

	return nil
}

// loadCheckpoint –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ checkpoint —Ñ–∞–π–ª–∞
// –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç nil, –µ—Å–ª–∏ checkpoint –Ω–µ –Ω–∞–π–¥–µ–Ω (–Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—á–∞–ª–∞)
func (n *Normalizer) loadCheckpoint(uploadID int) (*NormalizationCheckpoint, error) {
	if !n.enableCheckpoints {
		return nil, nil
	}

	checkpointPath := n.getCheckpointPath(uploadID)

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
	if _, err := os.Stat(checkpointPath); os.IsNotExist(err) {
		return nil, nil // Checkpoint –Ω–µ –Ω–∞–π–¥–µ–Ω - –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—á–∞–ª–∞
	}

	// –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
	data, err := os.ReadFile(checkpointPath)
	if err != nil {
		return nil, fmt.Errorf("failed to read checkpoint file: %w", err)
	}

	// –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –∏–∑ JSON
	var checkpoint NormalizationCheckpoint
	if err := json.Unmarshal(data, &checkpoint); err != nil {
		return nil, fmt.Errorf("failed to unmarshal checkpoint: %w", err)
	}

	log.Printf("Checkpoint –∑–∞–≥—Ä—É–∂–µ–Ω: –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å –ø–æ–∑–∏—Ü–∏–∏ %d/%d (%.1f%%)",
		checkpoint.ProcessedCount, checkpoint.TotalCount,
		float64(checkpoint.ProcessedCount)/float64(checkpoint.TotalCount)*100)
	n.sendEvent(fmt.Sprintf("–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å checkpoint: %d/%d –∑–∞–ø–∏—Å–µ–π", checkpoint.ProcessedCount, checkpoint.TotalCount))

	return &checkpoint, nil
}

// deleteCheckpoint —É–¥–∞–ª—è–µ—Ç checkpoint —Ñ–∞–π–ª –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
func (n *Normalizer) deleteCheckpoint(uploadID int) error {
	if !n.enableCheckpoints {
		return nil
	}

	checkpointPath := n.getCheckpointPath(uploadID)

	if err := os.Remove(checkpointPath); err != nil && !os.IsNotExist(err) {
		return fmt.Errorf("failed to delete checkpoint file: %w", err)
	}

	log.Printf("Checkpoint —É–¥–∞–ª–µ–Ω –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
	return nil
}

// GetCheckpointStatus –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å checkpoint –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
func (n *Normalizer) GetCheckpointStatus() map[string]interface{} {
	if !n.enableCheckpoints {
		return map[string]interface{}{
			"enabled":          false,
			"active":           false,
			"processed_count":  0,
			"total_count":      0,
			"progress_percent": 0.0,
		}
	}

	if n.currentCheckpoint == nil {
		return map[string]interface{}{
			"enabled":          true,
			"active":           false,
			"processed_count":  0,
			"total_count":      0,
			"progress_percent": 0.0,
		}
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∞–∫—Ç–∏–≤–µ–Ω –ª–∏ –ø—Ä–æ—Ü–µ—Å—Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
	// –ï—Å–ª–∏ –ø—Ä–æ—à–ª–æ –±–æ–ª–µ–µ 5 –º–∏–Ω—É—Ç —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–º
	active := false
	if !n.currentCheckpoint.LastSaveTime.IsZero() {
		timeSinceLastSave := time.Since(n.currentCheckpoint.LastSaveTime)
		active = timeSinceLastSave < 5*time.Minute && n.currentCheckpoint.ProcessedCount < n.currentCheckpoint.TotalCount
	}

	progressPercent := 0.0
	if n.currentCheckpoint.TotalCount > 0 {
		progressPercent = float64(n.currentCheckpoint.ProcessedCount) / float64(n.currentCheckpoint.TotalCount) * 100.0
	}

	var lastCheckpointTime *string
	if !n.currentCheckpoint.LastSaveTime.IsZero() {
		timeStr := n.currentCheckpoint.LastSaveTime.Format(time.RFC3339)
		lastCheckpointTime = &timeStr
	}

	var currentBatchID *string
	if n.currentCheckpoint.UploadID > 0 {
		batchID := fmt.Sprintf("upload_%d", n.currentCheckpoint.UploadID)
		currentBatchID = &batchID
	}

	return map[string]interface{}{
		"enabled":           true,
		"active":            active,
		"processed_count":   n.currentCheckpoint.ProcessedCount,
		"total_count":       n.currentCheckpoint.TotalCount,
		"progress_percent":  progressPercent,
		"last_checkpoint_time": lastCheckpointTime,
		"current_batch_id":    currentBatchID,
	}
}

